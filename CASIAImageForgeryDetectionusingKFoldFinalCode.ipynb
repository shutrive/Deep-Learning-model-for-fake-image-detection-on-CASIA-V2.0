{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Real vs Fake Images Detection with ELA(Error Level Analysis) and CNN**\n\nImporting all the libraries","metadata":{}},{"cell_type":"code","source":"#import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\n#import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n#from keras.callbacks import EarlyS\nfrom keras.callbacks import EarlyStopping\nfrom PIL import Image, ImageChops, ImageEnhance\nimport os\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-20T16:41:35.064275Z","iopub.execute_input":"2021-12-20T16:41:35.064630Z","iopub.status.idle":"2021-12-20T16:41:40.359218Z","shell.execute_reply.started":"2021-12-20T16:41:35.064600Z","shell.execute_reply":"2021-12-20T16:41:40.358227Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageChops, ImageEnhance\nimport os\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:41:40.362984Z","iopub.execute_input":"2021-12-20T16:41:40.363262Z","iopub.status.idle":"2021-12-20T16:41:40.367723Z","shell.execute_reply.started":"2021-12-20T16:41:40.363236Z","shell.execute_reply":"2021-12-20T16:41:40.366857Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**EDA**\n1. Raw Comparison","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\n%matplotlib inline\n\ntrain_dir = '../input/casia-dataset/CASIA2' # image folder\n\n# get the list of jpegs from sub image class folders\nreal_imgs = [fn for fn in os.listdir(f'{train_dir}/Au') if fn.endswith('jpg') or fn.endswith('png')]\nfake_imgs = [fn for fn in os.listdir(f'{train_dir}/Tp') if fn.endswith('jpg') or fn.endswith('png')]\n\n# randomly select 3 of each\nselect_real = np.random.choice(real_imgs, 3, replace = False)\nselect_fake = np.random.choice(fake_imgs, 3, replace = False)\n\n# plotting 2 x 3 image matrix\nfig = plt.figure(figsize = (8,6))\nfor i in range(6):\n    if i < 3:\n        fp = f'{train_dir}/Au/{select_real[i]}'\n        label = 'Authentic'\n    else:\n        fp = f'{train_dir}/Tp/{select_fake[i-3]}'\n        label = 'Tampered'\n    ax = fig.add_subplot(2, 3, i+1)\n    \n    # to plot without rescaling, remove target_size\n    fn = image.load_img(fp, target_size = (100,100), color_mode='rgb')\n    plt.imshow(fn, cmap='Greys_r')\n    plt.title(label)\n    plt.axis('off')\nplt.show()\n\n# also check the number of files here\nlen(real_imgs), len(fake_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:41:40.369268Z","iopub.execute_input":"2021-12-20T16:41:40.369936Z","iopub.status.idle":"2021-12-20T16:41:41.448979Z","shell.execute_reply.started":"2021-12-20T16:41:40.369894Z","shell.execute_reply":"2021-12-20T16:41:41.448033Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# making n X m matrix\ndef img2np(path, list_of_filename, size = (64, 64)):\n    # iterating through each file\n    for fn in list_of_filename:\n        fp = path + fn\n        current_image = image.load_img(fp, target_size = size, \n                                       color_mode = 'grayscale')\n        # covert image to a matrix\n        img_ts = image.img_to_array(current_image)\n        # turn that into a vector / 1D array\n        img_ts = [img_ts.ravel()]\n        try:\n            # concatenate different images\n            full_mat = np.concatenate((full_mat, img_ts))\n        except UnboundLocalError: \n            # if not assigned yet, assign one\n            full_mat = img_ts\n    return full_mat\n\n# run it on our folders\nreal_images = img2np(f'{train_dir}/Au/', real_imgs)\nfake_images = img2np(f'{train_dir}/Tp/', fake_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:41:41.450082Z","iopub.execute_input":"2021-12-20T16:41:41.450415Z","iopub.status.idle":"2021-12-20T16:45:47.376502Z","shell.execute_reply.started":"2021-12-20T16:41:41.450380Z","shell.execute_reply":"2021-12-20T16:45:47.375534Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def find_mean_img(full_mat, title, size = (64, 64)):\n    # calculate the average\n    mean_img = np.mean(full_mat, axis = 0)\n    # reshape it back to a matrix\n    mean_img = mean_img.reshape(size)\n    plt.imshow(mean_img, vmin=0, vmax=255, cmap='Greys_r')\n    plt.title(f'Average {title}')\n    plt.axis('off')\n    plt.show()\n    return mean_img\n\nnorm_mean = find_mean_img(real_images, 'Authentic')\npneu_mean = find_mean_img(fake_images, 'Fake')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:45:47.381183Z","iopub.execute_input":"2021-12-20T16:45:47.381475Z","iopub.status.idle":"2021-12-20T16:45:47.502738Z","shell.execute_reply.started":"2021-12-20T16:45:47.381447Z","shell.execute_reply":"2021-12-20T16:45:47.501890Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"2. Comparison between average of real and fake images","metadata":{}},{"cell_type":"code","source":"contrast_mean = norm_mean - pneu_mean\nplt.imshow(contrast_mean, cmap='bwr')\nplt.title(f'Difference Between Authentic & Fake Average')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:45:47.506903Z","iopub.execute_input":"2021-12-20T16:45:47.507314Z","iopub.status.idle":"2021-12-20T16:45:47.565732Z","shell.execute_reply.started":"2021-12-20T16:45:47.507271Z","shell.execute_reply":"2021-12-20T16:45:47.564863Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"3. EigenImages","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom math import ceil\n\ndef eigenimages(full_mat, title, n_comp = 0.7, size = (64, 64)):\n    # fit PCA to describe n_comp * variability in the class\n    pca = PCA(n_components = n_comp, whiten = True)\n    pca.fit(full_mat)\n    print('Number of PC: ', pca.n_components_)\n    return pca\n  \ndef plot_pca(pca, size = (64, 64)):\n    # plot eigenimages in a grid\n    n = pca.n_components_\n    fig = plt.figure(figsize=(8, 8))\n    r = int(n**.5)\n    c = ceil(n/ r)\n    for i in range(n):\n        ax = fig.add_subplot(r, c, i + 1, xticks = [], yticks = [])\n        ax.imshow(pca.components_[i].reshape(size), \n                  cmap='Greys_r')\n    plt.axis('off')\n    plt.show()\n    \nplot_pca(eigenimages(real_images, 'Authentic'))\nplot_pca(eigenimages(fake_images, 'Tampered'))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:45:47.567597Z","iopub.execute_input":"2021-12-20T16:45:47.567998Z","iopub.status.idle":"2021-12-20T16:46:25.896906Z","shell.execute_reply.started":"2021-12-20T16:45:47.567964Z","shell.execute_reply":"2021-12-20T16:46:25.896023Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**ELA (Error Level Analysis)**","metadata":{}},{"cell_type":"code","source":"def convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    ela_filename = 'temp_ela.png'\n    \n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality = quality)\n    temp_image = Image.open(temp_filename)\n    \n    ela_image = ImageChops.difference(image, temp_image)\n    \n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 / max_diff\n    \n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    \n    return ela_image","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-12-20T16:46:25.898205Z","iopub.execute_input":"2021-12-20T16:46:25.898665Z","iopub.status.idle":"2021-12-20T16:46:25.908455Z","shell.execute_reply.started":"2021-12-20T16:46:25.898628Z","shell.execute_reply":"2021-12-20T16:46:25.907802Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Open a real image","metadata":{}},{"cell_type":"code","source":"real_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Au/Au_ani_00001.jpg'\nImage.open(real_image_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:25.909929Z","iopub.execute_input":"2021-12-20T16:46:25.910390Z","iopub.status.idle":"2021-12-20T16:46:25.993056Z","shell.execute_reply.started":"2021-12-20T16:46:25.910350Z","shell.execute_reply":"2021-12-20T16:46:25.992230Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"After converting to ELA image","metadata":{}},{"cell_type":"code","source":"convert_to_ela_image(real_image_path, 90)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:25.994219Z","iopub.execute_input":"2021-12-20T16:46:25.994679Z","iopub.status.idle":"2021-12-20T16:46:26.065811Z","shell.execute_reply.started":"2021-12-20T16:46:25.994643Z","shell.execute_reply":"2021-12-20T16:46:26.064958Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Open a fake image","metadata":{}},{"cell_type":"code","source":"fake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nImage.open(fake_image_path)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:26.067430Z","iopub.execute_input":"2021-12-20T16:46:26.067796Z","iopub.status.idle":"2021-12-20T16:46:26.167458Z","shell.execute_reply.started":"2021-12-20T16:46:26.067748Z","shell.execute_reply":"2021-12-20T16:46:26.166679Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(fake_image_path, 90)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:26.168830Z","iopub.execute_input":"2021-12-20T16:46:26.169343Z","iopub.status.idle":"2021-12-20T16:46:26.284076Z","shell.execute_reply.started":"2021-12-20T16:46:26.169307Z","shell.execute_reply":"2021-12-20T16:46:26.283200Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Denoising**","metadata":{}},{"cell_type":"code","source":"\n# Color-image denoising\nfrom skimage.restoration import (denoise_wavelet,estimate_sigma)\nfrom skimage.util import random_noise\n# from sklearn.metrics import peak_signal_noise_ratio\nimport skimage.io\n\nimg_r=skimage.io.imread('../input/casia-dataset/CASIA2/Au/Au_ani_00001.jpg')\nimg_r=skimage.img_as_float(img_r) #converting image as float\n\n#sigma=0.35 #noise\n#imgn=random_noise(img,var=sigma**2) # adding noise\n\nsigma_est=estimate_sigma(img_r,multichannel=True,average_sigmas=True)  #Noise estimation\n\n# Denoising using Bayes\nimg_bayes=denoise_wavelet(img_r,method='BayesShrink',mode='soft',wavelet_levels=3,\n                          wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n\n\n#Denoising using Visushrink\nimg_visushrink=denoise_wavelet(img_r,method='VisuShrink',mode='soft',sigma=sigma_est/3,wavelet_levels=5,\n                               wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:26.285304Z","iopub.execute_input":"2021-12-20T16:46:26.285759Z","iopub.status.idle":"2021-12-20T16:46:26.883284Z","shell.execute_reply.started":"2021-12-20T16:46:26.285721Z","shell.execute_reply":"2021-12-20T16:46:26.882288Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import cv2\npsnr_noisy = cv2.PSNR(img_r,img_r)\npsnr_noisy","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:26.884751Z","iopub.execute_input":"2021-12-20T16:46:26.885366Z","iopub.status.idle":"2021-12-20T16:46:27.131695Z","shell.execute_reply.started":"2021-12-20T16:46:26.885311Z","shell.execute_reply":"2021-12-20T16:46:27.130888Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"psnr_bayes = cv2.PSNR(img_r,img_bayes)\npsnr_bayes","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:27.132990Z","iopub.execute_input":"2021-12-20T16:46:27.133324Z","iopub.status.idle":"2021-12-20T16:46:27.139961Z","shell.execute_reply.started":"2021-12-20T16:46:27.133284Z","shell.execute_reply":"2021-12-20T16:46:27.139043Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"psnr_visu = cv2.PSNR(img_r,img_visushrink)\npsnr_bayes","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:27.141624Z","iopub.execute_input":"2021-12-20T16:46:27.142373Z","iopub.status.idle":"2021-12-20T16:46:27.150493Z","shell.execute_reply.started":"2021-12-20T16:46:27.142335Z","shell.execute_reply":"2021-12-20T16:46:27.149631Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Plotting images\nplt.figure(figsize=(30,30))\n\n# plt.subplot(2,2,1)\n# plt.imshow(img,cmap=plt.cm.gray)\n# plt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,2)\nplt.imshow(img_r,cmap=plt.cm.gray)\nplt.title('Noisy Image',fontsize=30)\n\nplt.subplot(2,2,3)\nplt.imshow(img_bayes,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,4)\nplt.imshow(img_visushrink,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:27.152517Z","iopub.execute_input":"2021-12-20T16:46:27.152910Z","iopub.status.idle":"2021-12-20T16:46:28.351126Z","shell.execute_reply.started":"2021-12-20T16:46:27.152871Z","shell.execute_reply":"2021-12-20T16:46:28.349081Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print('PSNR[Original vs. Noisy Image]', psnr_noisy)\nprint('PSNR[Original vs. Denoised(VisuShrink)]', psnr_visu)\nprint('PSNR[Original vs. Denoised(Bayes)]', psnr_bayes)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:28.352317Z","iopub.execute_input":"2021-12-20T16:46:28.352746Z","iopub.status.idle":"2021-12-20T16:46:28.360413Z","shell.execute_reply.started":"2021-12-20T16:46:28.352711Z","shell.execute_reply":"2021-12-20T16:46:28.359535Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"DENOISING FAKE IMAGE","metadata":{}},{"cell_type":"code","source":"# Color-image denoising\nfrom skimage.restoration import (denoise_wavelet,estimate_sigma)\nfrom skimage.util import random_noise\n# from sklearn.metrics import peak_signal_noise_ratio\nimport skimage.io\n\nimg_f=skimage.io.imread('../input/casia-dataset/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg')\nimg_f=skimage.img_as_float(img_f) #converting image as float\n\n#sigma=0.35 #noise\n#imgn=random_noise(img,var=sigma**2) # adding noise\n\nsigma_est=estimate_sigma(img_f,multichannel=True,average_sigmas=True)  #Noise estimation\n\n# Denoising using Bayes\nimg_bayes=denoise_wavelet(img_f,method='BayesShrink',mode='soft',wavelet_levels=3,\n                          wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n\n\n#Denoising using Visushrink\nimg_visushrink=denoise_wavelet(img_f,method='VisuShrink',mode='soft',sigma=sigma_est/3,wavelet_levels=5,\n                               wavelet='coif5',multichannel=True,convert2ycbcr=True,rescale_sigma=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:28.362094Z","iopub.execute_input":"2021-12-20T16:46:28.363040Z","iopub.status.idle":"2021-12-20T16:46:28.594147Z","shell.execute_reply.started":"2021-12-20T16:46:28.362997Z","shell.execute_reply":"2021-12-20T16:46:28.593158Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import cv2\npsnr_noisy = cv2.PSNR(img_f,img_f)\npsnr_noisy","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:28.597433Z","iopub.execute_input":"2021-12-20T16:46:28.597694Z","iopub.status.idle":"2021-12-20T16:46:28.607578Z","shell.execute_reply.started":"2021-12-20T16:46:28.597667Z","shell.execute_reply":"2021-12-20T16:46:28.606887Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"psnr_bayes = cv2.PSNR(img_f,img_bayes)\npsnr_bayes","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:28.608816Z","iopub.execute_input":"2021-12-20T16:46:28.609190Z","iopub.status.idle":"2021-12-20T16:46:28.616738Z","shell.execute_reply.started":"2021-12-20T16:46:28.609151Z","shell.execute_reply":"2021-12-20T16:46:28.615627Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"psnr_visu = cv2.PSNR(img_f,img_visushrink)\npsnr_bayes","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:28.618267Z","iopub.execute_input":"2021-12-20T16:46:28.618864Z","iopub.status.idle":"2021-12-20T16:46:28.627275Z","shell.execute_reply.started":"2021-12-20T16:46:28.618819Z","shell.execute_reply":"2021-12-20T16:46:28.626357Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Plotting images\nplt.figure(figsize=(30,30))\n\n# plt.subplot(2,2,1)\n# plt.imshow(img,cmap=plt.cm.gray)\n# plt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,2)\nplt.imshow(img_f,cmap=plt.cm.gray)\nplt.title('Noisy Image',fontsize=30)\n\nplt.subplot(2,2,3)\nplt.imshow(img_bayes,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.subplot(2,2,4)\nplt.imshow(img_visushrink,cmap=plt.cm.gray)\nplt.title('Original Image',fontsize=30)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:28.628925Z","iopub.execute_input":"2021-12-20T16:46:28.629410Z","iopub.status.idle":"2021-12-20T16:46:30.052369Z","shell.execute_reply.started":"2021-12-20T16:46:28.629368Z","shell.execute_reply":"2021-12-20T16:46:30.049918Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print('PSNR[Original vs. Noisy Image]', psnr_noisy)\nprint('PSNR[Original vs. Denoised(VisuShrink)]', psnr_visu)\nprint('PSNR[Original vs. Denoised(Bayes)]', psnr_bayes)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:30.053809Z","iopub.execute_input":"2021-12-20T16:46:30.054296Z","iopub.status.idle":"2021-12-20T16:46:30.060455Z","shell.execute_reply.started":"2021-12-20T16:46:30.054260Z","shell.execute_reply":"2021-12-20T16:46:30.059694Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom skimage.restoration import (denoise_wavelet, estimate_sigma)\nfrom skimage import data, img_as_float\nfrom skimage.util import random_noise\nfrom skimage.metrics import peak_signal_noise_ratio\n\nnoisy=skimage.io.imread('../input/casia-dataset/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg')\nnoisy=skimage.img_as_float(noisy) \n# original = img_as_float(data.chelsea()[100:250, 50:300])\n\n# sigma = 0.12\n# noisy = random_noise(original, var=sigma**2)\n\nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(8, 5),\n                       sharex=True, sharey=True)\n\nplt.gray()\n\n# Estimate the average noise standard deviation across color channels.\nsigma_est = estimate_sigma(noisy,average_sigmas=True)\n# Due to clipping in random_noise, the estimate will be a bit smaller than the\n# specified sigma.\nprint(f'Estimated Gaussian noise standard deviation = {sigma_est}')\n\nim_bayes = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                           method='BayesShrink', mode='soft',\n                           rescale_sigma=True)\nim_visushrink = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                                method='VisuShrink', mode='soft',\n                                sigma=sigma_est, rescale_sigma=True)\n\n# VisuShrink is designed to eliminate noise with high probability, but this\n# results in a visually over-smooth appearance.  Repeat, specifying a reduction\n# in the threshold by factors of 2 and 4.\nim_visushrink2 = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                                 method='VisuShrink', mode='soft',\n                                 sigma=sigma_est/2, rescale_sigma=True)\nim_visushrink4 = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                                 method='VisuShrink', mode='soft',\n                                 sigma=sigma_est/4, rescale_sigma=True)\n\n# Compute PSNR as an indication of image quality\npsnr_noisy = peak_signal_noise_ratio(noisy, noisy)\npsnr_bayes = peak_signal_noise_ratio(noisy, im_bayes)\npsnr_visushrink = peak_signal_noise_ratio(noisy, im_visushrink)\npsnr_visushrink2 = peak_signal_noise_ratio(noisy, im_visushrink2)\npsnr_visushrink4 = peak_signal_noise_ratio(noisy, im_visushrink4)\n\nax[0, 0].imshow(noisy)\nax[0, 0].axis('off')\nax[0, 0].set_title(f'Fake Image')\nax[0, 1].imshow(im_bayes)\nax[0, 1].axis('off')\nax[0, 1].set_title(\n    f'Wavelet denoising\\n(BayesShrink)\\nPSNR={psnr_bayes:0.4g}')\nax[0, 2].imshow(im_visushrink)\nax[0, 2].axis('off')\nax[0, 2].set_title(\n    'Wavelet denoising\\n(VisuShrink, $\\\\sigma=\\\\sigma_{est}$)\\n'\n     'PSNR=%0.4g' % psnr_visushrink)\nax[1, 0].imshow(noisy)\nax[1, 0].axis('off')\nax[1, 0].set_title('Fake Image')\nax[1, 1].imshow(im_visushrink2)\nax[1, 1].axis('off')\nax[1, 1].set_title(\n    'Wavelet denoising\\n(VisuShrink, $\\\\sigma=\\\\sigma_{est}/2$)\\n'\n     'PSNR=%0.4g' % psnr_visushrink2)\nax[1, 2].imshow(im_visushrink4)\nax[1, 2].axis('off')\nax[1, 2].set_title(\n    'Wavelet denoising\\n(VisuShrink, $\\\\sigma=\\\\sigma_{est}/4$)\\n'\n     'PSNR=%0.4g' % psnr_visushrink4)\nfig.tight_layout()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:30.061753Z","iopub.execute_input":"2021-12-20T16:46:30.062296Z","iopub.status.idle":"2021-12-20T16:46:31.245588Z","shell.execute_reply.started":"2021-12-20T16:46:30.062259Z","shell.execute_reply":"2021-12-20T16:46:31.244689Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom skimage.restoration import (denoise_wavelet, estimate_sigma)\nfrom skimage import data, img_as_float\nfrom skimage.util import random_noise\nfrom skimage.metrics import peak_signal_noise_ratio\n\nnoisy=skimage.io.imread('../input/casia-dataset/CASIA2/Au/Au_ani_00001.jpg')\nnoisy=skimage.img_as_float(noisy) \n# original = img_as_float(data.chelsea()[100:250, 50:300])\n\n# sigma = 0.12\n# noisy = random_noise(original, var=sigma**2)\n\nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(8, 5),\n                       sharex=True, sharey=True)\n\nplt.gray()\n\n# Estimate the average noise standard deviation across color channels.\nsigma_est = estimate_sigma(noisy,average_sigmas=True)\n# Due to clipping in random_noise, the estimate will be a bit smaller than the\n# specified sigma.\nprint(f'Estimated Gaussian noise standard deviation = {sigma_est}')\n\nim_bayes = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                           method='BayesShrink', mode='soft',\n                           rescale_sigma=True)\nim_visushrink = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                                method='VisuShrink', mode='soft',\n                                sigma=sigma_est, rescale_sigma=True)\n\n# VisuShrink is designed to eliminate noise with high probability, but this\n# results in a visually over-smooth appearance.  Repeat, specifying a reduction\n# in the threshold by factors of 2 and 4.\nim_visushrink2 = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                                 method='VisuShrink', mode='soft',\n                                 sigma=sigma_est/2, rescale_sigma=True)\nim_visushrink4 = denoise_wavelet(noisy, convert2ycbcr=True,multichannel=True,\n                                 method='VisuShrink', mode='soft',\n                                 sigma=sigma_est/4, rescale_sigma=True)\n\n# Compute PSNR as an indication of image quality\npsnr_noisy = peak_signal_noise_ratio(noisy, noisy)\npsnr_bayes = peak_signal_noise_ratio(noisy, im_bayes)\npsnr_visushrink = peak_signal_noise_ratio(noisy, im_visushrink)\npsnr_visushrink2 = peak_signal_noise_ratio(noisy, im_visushrink2)\npsnr_visushrink4 = peak_signal_noise_ratio(noisy, im_visushrink4)\n\nax[0, 0].imshow(noisy)\nax[0, 0].axis('off')\nax[0, 0].set_title(f'Real Image')\nax[0, 1].imshow(im_bayes)\nax[0, 1].axis('off')\nax[0, 1].set_title(\n    f'Wavelet denoising\\n(BayesShrink)\\nPSNR={psnr_bayes:0.4g}')\nax[0, 2].imshow(im_visushrink)\nax[0, 2].axis('off')\nax[0, 2].set_title(\n    'Wavelet denoising\\n(VisuShrink, $\\\\sigma=\\\\sigma_{est}$)\\n'\n     'PSNR=%0.4g' % psnr_visushrink)\nax[1, 0].imshow(noisy)\nax[1, 0].axis('off')\nax[1, 0].set_title('Real Image')\nax[1, 1].imshow(im_visushrink2)\nax[1, 1].axis('off')\nax[1, 1].set_title(\n    'Wavelet denoising\\n(VisuShrink, $\\\\sigma=\\\\sigma_{est}/2$)\\n'\n     'PSNR=%0.4g' % psnr_visushrink2)\nax[1, 2].imshow(im_visushrink4)\nax[1, 2].axis('off')\nax[1, 2].set_title(\n    'Wavelet denoising\\n(VisuShrink, $\\\\sigma=\\\\sigma_{est}/4$)\\n'\n     'PSNR=%0.4g' % psnr_visushrink4)\nfig.tight_layout()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:31.246952Z","iopub.execute_input":"2021-12-20T16:46:31.247479Z","iopub.status.idle":"2021-12-20T16:46:32.163651Z","shell.execute_reply.started":"2021-12-20T16:46:31.247442Z","shell.execute_reply":"2021-12-20T16:46:32.162629Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\ndef my_metrics(y_true, y_pred):\n    accuracy=accuracy_score(y_true, y_pred)\n    precision=precision_score(y_true, y_pred,average='weighted')\n    f1Score=f1_score(y_true, y_pred, average='weighted') \n    print(\"Accuracy  : {}\".format(accuracy))\n    print(\"Precision : {}\".format(precision))\n    print(\"f1Score : {}\".format(f1Score))\n    cm=confusion_matrix(y_true, y_pred)\n    print(cm)\n    return accuracy, precision, f1Score\nprint(\"***Performance on Validation data***\")    \n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:32.165229Z","iopub.execute_input":"2021-12-20T16:46:32.165615Z","iopub.status.idle":"2021-12-20T16:46:32.177823Z","shell.execute_reply.started":"2021-12-20T16:46:32.165575Z","shell.execute_reply":"2021-12-20T16:46:32.176975Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Image Augmentation******","metadata":{}},{"cell_type":"code","source":"from numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\n# load the image\nimg = load_img('../input/casia-dataset/CASIA2/Au/Au_ani_00001.jpg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale = 1./255,\n        shear_range = 0.2,\n        zoom_range = 0.2,\n        horizontal_flip = True)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n\ndef do_plot(ax):\n    ax.plot([1,2,3], 'k.')\nfrom matplotlib import gridspec\ngs = gridspec.GridSpec(3, 5)\nfig = plt.figure(figsize=(15,8))\nfor n in range(15):\n    ax = fig.add_subplot(gs[n])\n     # generate batch of images\n    batch = it.next()\n   # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')     # plot raw pixel data\n    pyplot.imshow(image)\n    do_plot(ax)\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:32.179509Z","iopub.execute_input":"2021-12-20T16:46:32.179978Z","iopub.status.idle":"2021-12-20T16:46:34.584675Z","shell.execute_reply.started":"2021-12-20T16:46:32.179933Z","shell.execute_reply":"2021-12-20T16:46:34.583896Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Dataset Preparation","metadata":{}},{"cell_type":"code","source":"image_size = (128, 128)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:34.586222Z","iopub.execute_input":"2021-12-20T16:46:34.586591Z","iopub.status.idle":"2021-12-20T16:46:34.591280Z","shell.execute_reply.started":"2021-12-20T16:46:34.586553Z","shell.execute_reply":"2021-12-20T16:46:34.590437Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def prepare_image(image_path):\n    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:34.592655Z","iopub.execute_input":"2021-12-20T16:46:34.593266Z","iopub.status.idle":"2021-12-20T16:46:34.601513Z","shell.execute_reply.started":"2021-12-20T16:46:34.593228Z","shell.execute_reply":"2021-12-20T16:46:34.600817Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X = [] # ELA converted images\nY = [] # 0 for fake, 1 for real","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:34.604728Z","iopub.execute_input":"2021-12-20T16:46:34.605013Z","iopub.status.idle":"2021-12-20T16:46:34.610962Z","shell.execute_reply.started":"2021-12-20T16:46:34.604988Z","shell.execute_reply":"2021-12-20T16:46:34.610148Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Au => Total Images 7354, Take 2100 random images from the list\nTp => Total Images 2064","metadata":{}},{"cell_type":"code","source":"import random\npath = '/kaggle/input/casia-dataset/CASIA2/Au/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))\n            Y.append(1)\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\nrandom.shuffle(X)\n# X = X[:2100]\n# Y = Y[:2100]\nprint(len(X), len(Y))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:46:34.619073Z","iopub.execute_input":"2021-12-20T16:46:34.619322Z","iopub.status.idle":"2021-12-20T16:48:27.745702Z","shell.execute_reply.started":"2021-12-20T16:46:34.619298Z","shell.execute_reply":"2021-12-20T16:48:27.744976Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/casia-dataset/CASIA2/Tp/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))\n            Y.append(0)\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\nprint(len(X), len(Y))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:48:27.748810Z","iopub.execute_input":"2021-12-20T16:48:27.749075Z","iopub.status.idle":"2021-12-20T16:49:11.929045Z","shell.execute_reply.started":"2021-12-20T16:48:27.749048Z","shell.execute_reply":"2021-12-20T16:49:11.927592Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\nY = to_categorical(Y, 2)\nX = X.reshape(-1, 128, 128, 3)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-12-20T16:49:11.930456Z","iopub.execute_input":"2021-12-20T16:49:11.930808Z","iopub.status.idle":"2021-12-20T16:49:13.145072Z","shell.execute_reply.started":"2021-12-20T16:49:11.930754Z","shell.execute_reply":"2021-12-20T16:49:13.144151Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:13.146363Z","iopub.execute_input":"2021-12-20T16:49:13.146704Z","iopub.status.idle":"2021-12-20T16:49:13.161694Z","shell.execute_reply.started":"2021-12-20T16:49:13.146669Z","shell.execute_reply":"2021-12-20T16:49:13.160726Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Train Test split with 80:20 ratio","metadata":{}},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\nX = X.reshape(-1,1,1,1)\nprint(len(X_train), len(Y_train))\nprint(len(X_val), len(Y_val))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:13.163223Z","iopub.execute_input":"2021-12-20T16:49:13.163781Z","iopub.status.idle":"2021-12-20T16:49:14.206402Z","shell.execute_reply.started":"2021-12-20T16:49:13.163743Z","shell.execute_reply":"2021-12-20T16:49:14.205516Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"CNN Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(MaxPool2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = 'softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:14.207798Z","iopub.execute_input":"2021-12-20T16:49:14.208374Z","iopub.status.idle":"2021-12-20T16:49:14.217710Z","shell.execute_reply.started":"2021-12-20T16:49:14.208324Z","shell.execute_reply":"2021-12-20T16:49:14.216853Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:14.219062Z","iopub.execute_input":"2021-12-20T16:49:14.219658Z","iopub.status.idle":"2021-12-20T16:49:16.332861Z","shell.execute_reply.started":"2021-12-20T16:49:14.219617Z","shell.execute_reply":"2021-12-20T16:49:16.332113Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nbatch_size = 32\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:16.335215Z","iopub.execute_input":"2021-12-20T16:49:16.335566Z","iopub.status.idle":"2021-12-20T16:49:16.340567Z","shell.execute_reply.started":"2021-12-20T16:49:16.335531Z","shell.execute_reply":"2021-12-20T16:49:16.338426Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\noptimizer = Adam(lr = init_lr, decay = init_lr/epochs)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:16.342069Z","iopub.execute_input":"2021-12-20T16:49:16.342579Z","iopub.status.idle":"2021-12-20T16:49:16.350181Z","shell.execute_reply.started":"2021-12-20T16:49:16.342530Z","shell.execute_reply":"2021-12-20T16:49:16.349229Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:16.353186Z","iopub.execute_input":"2021-12-20T16:49:16.353493Z","iopub.status.idle":"2021-12-20T16:49:16.369099Z","shell.execute_reply.started":"2021-12-20T16:49:16.353467Z","shell.execute_reply":"2021-12-20T16:49:16.368371Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor = 'val_acc',\n                              min_delta = 0,\n                              patience = 2,\n                              verbose = 0,\n                              mode = 'auto')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:16.371864Z","iopub.execute_input":"2021-12-20T16:49:16.372846Z","iopub.status.idle":"2021-12-20T16:49:16.377562Z","shell.execute_reply.started":"2021-12-20T16:49:16.372414Z","shell.execute_reply":"2021-12-20T16:49:16.376687Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(X_train,\n                 Y_train,\n                 batch_size = batch_size,\n                 epochs = epochs,\n                validation_data = (X_val, Y_val),\n                callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:49:16.378879Z","iopub.execute_input":"2021-12-20T16:49:16.379318Z","iopub.status.idle":"2021-12-20T16:51:46.183656Z","shell.execute_reply.started":"2021-12-20T16:49:16.379283Z","shell.execute_reply":"2021-12-20T16:51:46.182898Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model.save('model_casia_run1.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:46.185379Z","iopub.execute_input":"2021-12-20T16:51:46.185741Z","iopub.status.idle":"2021-12-20T16:51:47.004118Z","shell.execute_reply.started":"2021-12-20T16:51:46.185701Z","shell.execute_reply":"2021-12-20T16:51:47.003344Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:47.005430Z","iopub.execute_input":"2021-12-20T16:51:47.005805Z","iopub.status.idle":"2021-12-20T16:51:47.265713Z","shell.execute_reply.started":"2021-12-20T16:51:47.005754Z","shell.execute_reply":"2021-12-20T16:51:47.264835Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:47.267463Z","iopub.execute_input":"2021-12-20T16:51:47.268053Z","iopub.status.idle":"2021-12-20T16:51:47.279308Z","shell.execute_reply.started":"2021-12-20T16:51:47.268012Z","shell.execute_reply":"2021-12-20T16:51:47.278610Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:47.280962Z","iopub.execute_input":"2021-12-20T16:51:47.281366Z","iopub.status.idle":"2021-12-20T16:51:48.450280Z","shell.execute_reply.started":"2021-12-20T16:51:47.281318Z","shell.execute_reply":"2021-12-20T16:51:48.449450Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"Prediction","metadata":{}},{"cell_type":"code","source":"valAcc, valPrec, valFScore = my_metrics(Y_true, Y_pred_classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:48.451769Z","iopub.execute_input":"2021-12-20T16:51:48.452118Z","iopub.status.idle":"2021-12-20T16:51:48.467182Z","shell.execute_reply.started":"2021-12-20T16:51:48.452089Z","shell.execute_reply":"2021-12-20T16:51:48.466465Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"class_names = ['fake', 'real']","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:48.468527Z","iopub.execute_input":"2021-12-20T16:51:48.469027Z","iopub.status.idle":"2021-12-20T16:51:48.473313Z","shell.execute_reply.started":"2021-12-20T16:51:48.468988Z","shell.execute_reply":"2021-12-20T16:51:48.472232Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"real_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Au/Au_ani_00001.jpg'\nimage = prepare_image(real_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:48.474813Z","iopub.execute_input":"2021-12-20T16:51:48.475496Z","iopub.status.idle":"2021-12-20T16:51:48.551661Z","shell.execute_reply.started":"2021-12-20T16:51:48.475456Z","shell.execute_reply":"2021-12-20T16:51:48.550873Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"fake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nimage = prepare_image(fake_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:48.553636Z","iopub.execute_input":"2021-12-20T16:51:48.554002Z","iopub.status.idle":"2021-12-20T16:51:48.617714Z","shell.execute_reply.started":"2021-12-20T16:51:48.553965Z","shell.execute_reply":"2021-12-20T16:51:48.616979Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"fake_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Tp/')\ncorrect = 0\ntotal = 0\nfor file_name in fake_image:\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        fake_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Tp/', file_name)\n        image = prepare_image(fake_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total += 1\n        if y_pred_class == 0:\n            correct += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T16:51:48.620707Z","iopub.execute_input":"2021-12-20T16:51:48.620990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Au/')\ncorrect_r = 0\ntotal_r = 0\nfor file_name in real_image:\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        real_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Au/', file_name)\n        image = prepare_image(real_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total_r += 1\n        if y_pred_class == 1:\n            correct_r += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","metadata":{"execution":{"iopub.status.idle":"2021-12-20T17:00:49.963135Z","shell.execute_reply.started":"2021-12-20T16:53:57.428608Z","shell.execute_reply":"2021-12-20T17:00:49.962215Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"correct += correct_r\ntotal += total_r\nprint(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:49.964346Z","iopub.execute_input":"2021-12-20T17:00:49.964682Z","iopub.status.idle":"2021-12-20T17:00:49.971694Z","shell.execute_reply.started":"2021-12-20T17:00:49.964648Z","shell.execute_reply":"2021-12-20T17:00:49.969208Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print(len(X_train), len(Y_train))\nprint(len(X_val), len(Y_val))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:49.973143Z","iopub.execute_input":"2021-12-20T17:00:49.973888Z","iopub.status.idle":"2021-12-20T17:00:49.981656Z","shell.execute_reply.started":"2021-12-20T17:00:49.973829Z","shell.execute_reply":"2021-12-20T17:00:49.980754Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2,VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,Dropout,MaxPooling2D\nfrom tensorflow.keras.regularizers import l1,l2,l1_l2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Lambda\nfrom keras.layers.embeddings import Embedding\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimage_size = [128, 128]\nmodel=VGG16(input_shape=image_size + [3],include_top=False,weights='imagenet')\nfor layer in model.layers:\n    layer.trainable=False\n    \nmodel.summary()\ndef layer_adder(bottom_model, num_classes):\n    top_model= bottom_model.output\n    top_model= GlobalAveragePooling2D()(top_model)\n    top_model = layers.Dense(4096, activation = 'relu')(top_model)# we can add a new fully connected layer but it will increase the execution time.\n    top_model = layers.Dense(4096, activation = 'relu')(top_model)\n    top_model = layers.Dense(1000, activation = 'relu')(top_model)\n    #x=Dropout(0.25)(x)\n    top_model = layers.Dense(num_classes,activation = 'softmax')(top_model) # adding the output layer with softmax function as this is a multi label classification problem.\n    return top_model\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:49.983366Z","iopub.execute_input":"2021-12-20T17:00:49.984001Z","iopub.status.idle":"2021-12-20T17:00:50.702787Z","shell.execute_reply.started":"2021-12-20T17:00:49.983963Z","shell.execute_reply":"2021-12-20T17:00:50.702000Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"FC_head =layer_adder(model, 2)\nmodel = Model(inputs = model.input, outputs = FC_head)\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:50.706716Z","iopub.execute_input":"2021-12-20T17:00:50.707023Z","iopub.status.idle":"2021-12-20T17:00:50.757412Z","shell.execute_reply.started":"2021-12-20T17:00:50.706995Z","shell.execute_reply":"2021-12-20T17:00:50.756646Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nbatch_size = 20","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:50.759456Z","iopub.execute_input":"2021-12-20T17:00:50.759824Z","iopub.status.idle":"2021-12-20T17:00:50.768084Z","shell.execute_reply.started":"2021-12-20T17:00:50.759770Z","shell.execute_reply":"2021-12-20T17:00:50.767276Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\noptimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n\nmodel.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nearly_stopping = EarlyStopping(monitor = 'val_acc',\n                              min_delta = 0,\n                              patience = 2,\n                              verbose = 0,\n                              mode = 'auto')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:50.770551Z","iopub.execute_input":"2021-12-20T17:00:50.770920Z","iopub.status.idle":"2021-12-20T17:00:50.786053Z","shell.execute_reply.started":"2021-12-20T17:00:50.770881Z","shell.execute_reply":"2021-12-20T17:00:50.785290Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(X_train,\n                 Y_train,\n                 batch_size = batch_size,\n                 epochs = epochs,\n                validation_data = (X_val, Y_val),\n                callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:00:50.787465Z","iopub.execute_input":"2021-12-20T17:00:50.787903Z","iopub.status.idle":"2021-12-20T17:04:23.361397Z","shell.execute_reply.started":"2021-12-20T17:00:50.787862Z","shell.execute_reply":"2021-12-20T17:04:23.360089Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:23.363358Z","iopub.execute_input":"2021-12-20T17:04:23.364210Z","iopub.status.idle":"2021-12-20T17:04:23.870083Z","shell.execute_reply.started":"2021-12-20T17:04:23.364167Z","shell.execute_reply":"2021-12-20T17:04:23.869240Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:23.871340Z","iopub.execute_input":"2021-12-20T17:04:23.871864Z","iopub.status.idle":"2021-12-20T17:04:23.883105Z","shell.execute_reply.started":"2021-12-20T17:04:23.871823Z","shell.execute_reply":"2021-12-20T17:04:23.882284Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:23.886383Z","iopub.execute_input":"2021-12-20T17:04:23.886650Z","iopub.status.idle":"2021-12-20T17:04:26.472232Z","shell.execute_reply.started":"2021-12-20T17:04:23.886624Z","shell.execute_reply":"2021-12-20T17:04:26.471528Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"\nclass_names = ['fake', 'real']","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:26.473748Z","iopub.execute_input":"2021-12-20T17:04:26.474057Z","iopub.status.idle":"2021-12-20T17:04:26.478467Z","shell.execute_reply.started":"2021-12-20T17:04:26.474028Z","shell.execute_reply":"2021-12-20T17:04:26.477032Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"valAcc, valPrec, valFScore = my_metrics(Y_true, Y_pred_classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:26.479685Z","iopub.execute_input":"2021-12-20T17:04:26.480205Z","iopub.status.idle":"2021-12-20T17:04:26.497142Z","shell.execute_reply.started":"2021-12-20T17:04:26.480165Z","shell.execute_reply":"2021-12-20T17:04:26.496469Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"real_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Au/Au_ani_00001.jpg'\nimage = prepare_image(real_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:26.498342Z","iopub.execute_input":"2021-12-20T17:04:26.498871Z","iopub.status.idle":"2021-12-20T17:04:26.692664Z","shell.execute_reply.started":"2021-12-20T17:04:26.498827Z","shell.execute_reply":"2021-12-20T17:04:26.691276Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"fake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nimage = prepare_image(fake_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:26.694123Z","iopub.execute_input":"2021-12-20T17:04:26.694471Z","iopub.status.idle":"2021-12-20T17:04:26.758376Z","shell.execute_reply.started":"2021-12-20T17:04:26.694432Z","shell.execute_reply":"2021-12-20T17:04:26.757499Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"fake_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Tp/')\ncorrect = 0\ntotal = 0\nfor file_name in fake_image:\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        fake_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Tp/', file_name)\n        image = prepare_image(fake_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total += 1\n        if y_pred_class == 0:\n            correct += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:04:26.759754Z","iopub.execute_input":"2021-12-20T17:04:26.760338Z","iopub.status.idle":"2021-12-20T17:06:20.159155Z","shell.execute_reply.started":"2021-12-20T17:04:26.760299Z","shell.execute_reply":"2021-12-20T17:06:20.158244Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"RESNET50","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2,VGG16\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,Dropout,MaxPooling2D\nfrom tensorflow.keras.regularizers import l1,l2,l1_l2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Lambda\nfrom keras.layers.embeddings import Embedding\nIMAGE_RESIZE = 224\nRESNET50_POOLING_AVERAGE = 'avg'\nDENSE_LAYER_ACTIVATION = 'softmax'\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ndef buil_model():  \n    model = Sequential()\n\n    # 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n    # NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n    model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n\n    # 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n    model.add(Dense(2, activation = DENSE_LAYER_ACTIVATION))\n\n    # Say not to train first layer (ResNet) model as it is already trained\n    model.layers[0].trainable = False\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:06:20.160463Z","iopub.execute_input":"2021-12-20T17:06:20.160978Z","iopub.status.idle":"2021-12-20T17:06:20.171582Z","shell.execute_reply.started":"2021-12-20T17:06:20.160939Z","shell.execute_reply":"2021-12-20T17:06:20.170853Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:06:20.173118Z","iopub.execute_input":"2021-12-20T17:06:20.173673Z","iopub.status.idle":"2021-12-20T17:06:20.243043Z","shell.execute_reply.started":"2021-12-20T17:06:20.173595Z","shell.execute_reply":"2021-12-20T17:06:20.241798Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\noptimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n\nmodel.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nearly_stopping = EarlyStopping(monitor = 'val_acc',\n                              min_delta = 0,\n                              patience = 2,\n                              verbose = 0,\n                              mode = 'auto')\nhist = model.fit(X_train,\n                 Y_train,\n                 batch_size = batch_size,\n                 epochs = epochs,\n                validation_data = (X_val, Y_val),\n                callbacks = [early_stopping])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:06:20.244956Z","iopub.execute_input":"2021-12-20T17:06:20.245278Z","iopub.status.idle":"2021-12-20T17:08:20.847764Z","shell.execute_reply.started":"2021-12-20T17:06:20.245244Z","shell.execute_reply":"2021-12-20T17:08:20.847033Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:08:20.850905Z","iopub.execute_input":"2021-12-20T17:08:20.851166Z","iopub.status.idle":"2021-12-20T17:08:21.117667Z","shell.execute_reply.started":"2021-12-20T17:08:20.851139Z","shell.execute_reply":"2021-12-20T17:08:21.116861Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))\n\n\nclass_names = ['fake', 'real']","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:08:21.119833Z","iopub.execute_input":"2021-12-20T17:08:21.120386Z","iopub.status.idle":"2021-12-20T17:08:22.044257Z","shell.execute_reply.started":"2021-12-20T17:08:21.120345Z","shell.execute_reply":"2021-12-20T17:08:22.043498Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"valAcc, valPrec, valFScore = my_metrics(Y_true, Y_pred_classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:08:22.045869Z","iopub.execute_input":"2021-12-20T17:08:22.046207Z","iopub.status.idle":"2021-12-20T17:08:22.060906Z","shell.execute_reply.started":"2021-12-20T17:08:22.046172Z","shell.execute_reply":"2021-12-20T17:08:22.059879Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"real_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Au/Au_ani_00001.jpg'\nimage = prepare_image(real_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:08:22.062331Z","iopub.execute_input":"2021-12-20T17:08:22.062755Z","iopub.status.idle":"2021-12-20T17:08:22.120302Z","shell.execute_reply.started":"2021-12-20T17:08:22.062714Z","shell.execute_reply":"2021-12-20T17:08:22.119278Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"fake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nimage = prepare_image(fake_image_path)\nimage = image.reshape(-1, 128, 128, 3)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:08:22.121464Z","iopub.execute_input":"2021-12-20T17:08:22.121819Z","iopub.status.idle":"2021-12-20T17:08:22.187271Z","shell.execute_reply.started":"2021-12-20T17:08:22.121760Z","shell.execute_reply":"2021-12-20T17:08:22.186533Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"fake_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Tp/')\ncorrect = 0\ntotal = 0\nfor file_name in fake_image:\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        fake_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Tp/', file_name)\n        image = prepare_image(fake_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total += 1\n        if y_pred_class == 0:\n            correct += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T17:08:22.192333Z","iopub.execute_input":"2021-12-20T17:08:22.192766Z","iopub.status.idle":"2021-12-20T17:10:09.823401Z","shell.execute_reply.started":"2021-12-20T17:08:22.192720Z","shell.execute_reply":"2021-12-20T17:10:09.821681Z"},"trusted":true},"execution_count":78,"outputs":[]}]}